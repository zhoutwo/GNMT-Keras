{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhouz2/.conda/envs/rbenv/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input, LSTM, Dense, Dropout, Conv1D, Flatten, MaxPooling1D, Reshape, Activation, Embedding, TimeDistributed\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('reuters.csv', delimiter='\\t', names=['id', 'timestamp', 'title', 'url', 'first_line'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 10000  # Number of epochs to train for.\n",
    "latent_dim = 1024  # Latent dimensionality of the encoding space (number of nodes per LSTM layer).\n",
    "num_samples = len(df) #min(2, len(df))  # Number of samples to train on.\n",
    "num_test_samples = 20\n",
    "num_conv = 8 # Number of Conv layers\n",
    "num_dense = num_conv\n",
    "initial_num_filters = 20 # Initial number of filters; will double after every conv layer\n",
    "use_dropout = False\n",
    "dense_size = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = df['first_line'][:num_samples]\n",
    "output_texts = df['title'][:num_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = input_texts.apply(lambda i: i.strip().lower() + ' \\n')\n",
    "output_texts = output_texts.apply(lambda o: '\\t '+ o.strip().lower() + ' \\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~', oov_token='<unk>')\n",
    "tokenizer.fit_on_texts(input_texts)\n",
    "tokenizer.fit_on_texts(output_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "output_sequences = tokenizer.texts_to_sequences(output_texts)\n",
    "word_id_dict = tokenizer.word_index\n",
    "id_word_dict = dict()\n",
    "for k in word_id_dict:\n",
    "    id_word_dict[word_id_dict[k]] = k;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(input_texts)\n",
    "max_encoder_seq_length = max([len(seq) for seq in input_sequences])\n",
    "max_decoder_seq_length = max([len(seq) for seq in output_sequences])\n",
    "num_dict_size = len(tokenizer.word_index)\n",
    "# num_input_tokens = len(input_dict)\n",
    "# num_output_tokens = len(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 52302\n",
      "Max sequence length for inputs: 1107\n",
      "Max sequence length for outputs: 25\n",
      "Number of words in the dictionary (including OOV token): 44340\n"
     ]
    }
   ],
   "source": [
    "print('Number of samples:', num_samples)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "# print('Num of tokens for inputs:', num_input_tokens)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "# print('Num of tokens for outputs:', num_output_tokens)\n",
    "print('Number of words in the dictionary (including OOV token):', num_dict_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_input_data = np.zeros((num_samples, max_encoder_seq_length, num_input_tokens),dtype='float32')\n",
    "# reversed_encoder_input_data = np.zeros((num_samples, max_encoder_seq_length, num_input_tokens),dtype='float32')\n",
    "# decoder_input_data = np.zeros((num_samples, max_decoder_seq_length, num_output_tokens),dtype='float32')\n",
    "# decoder_target_data = np.zeros((num_samples, max_decoder_seq_length, num_output_tokens),dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(num_samples):\n",
    "#     input_text = input_tokenizer.texts_to_sequences(input_texts[i])\n",
    "#     input_text = input_dict\n",
    "#     encoder_input_data[i, :, :] = input_tokenizer.texts_to_sequences(input_texts[i])\n",
    "#     reversed_encoder_input_data[i, :, :] = encoder_input_data[i, ::-1, :]\n",
    "#     decoder_input_data[i, :, :] = output_tokenizer.texts_to_sequences(output_texts[i])\n",
    "#     decoder_target_data[i, :, :] = np.row(decoder_input_data[i, :, :], 1)\n",
    "#     decoder_target_data[i, 0, :] = 0;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 1107, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1105, 20)          80        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 552, 20)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 550, 40)           2440      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 275, 40)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 273, 80)           9680      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 136, 80)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 134, 160)          38560     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 67, 160)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 65, 320)           153920    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 32, 320)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 30, 640)           615040    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 15, 640)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 13, 1280)          2458880   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 6, 1280)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 4, 2560)           9832960   \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 2, 2560)           0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 5120)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              5243904   \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1024)              1049600   \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 25)                25625     \n",
      "=================================================================\n",
      "Total params: 24,678,689\n",
      "Trainable params: 24,678,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## Baseline 2: CNN\n",
    "# Define an input sequence and process it.\n",
    "model = Sequential()\n",
    "model.add(Reshape((max_encoder_seq_length, 1), input_shape=(max_encoder_seq_length,)))\n",
    "num_filters = initial_num_filters\n",
    "for _ in range(num_conv):\n",
    "    model.add(Conv1D(filters=num_filters, kernel_size=3, activation='relu'))\n",
    "    num_filters *= 2\n",
    "    model.add(MaxPooling1D())\n",
    "    if use_dropout:\n",
    "        model.add(Dropout(0.5))\n",
    "        \n",
    "model.add(Flatten())\n",
    "for _ in range(num_conv-1):\n",
    "    model.add(Dense(dense_size, activation='relu'))\n",
    "model.add(Dense(max_decoder_seq_length, activation='relu'))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "model.summary()\n",
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "# model = Model([encoder_inputs, decoder_inputs], decoder_outputs)# Compile & run training\n",
    "# model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# model.summary()\n",
    "# SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = np.zeros((num_samples, max_encoder_seq_length), dtype='int32')\n",
    "decoder_target_data = np.zeros((num_samples, max_decoder_seq_length), dtype='int32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(num_samples):\n",
    "    encoder_input_data[k][:len(input_sequences[k])] = input_sequences[k][:]\n",
    "    decoder_target_data[k][:len(output_sequences[k])-1] = output_sequences[k][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoder_input_data = encoder_input_data.reshape((*encoder_input_data.shape, 1))\n",
    "# decoder_input_data = decoder_input_data.reshape((*decoder_input_data.shape, 1))\n",
    "# decoder_target_data = decoder_target_data.reshape((*decoder_target_data.shape, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "52302/52302 [==============================] - 33s 630us/step - loss: 13676110.6950\n",
      "Epoch 2/10000\n",
      "52302/52302 [==============================] - 28s 542us/step - loss: 12991241.3586\n",
      "Epoch 3/10000\n",
      "52302/52302 [==============================] - 29s 547us/step - loss: 24982849.4500\n",
      "Epoch 4/10000\n",
      "52302/52302 [==============================] - 28s 538us/step - loss: 13032691.5608\n",
      "Epoch 5/10000\n",
      "52302/52302 [==============================] - 28s 539us/step - loss: 12944545.3266\n",
      "Epoch 6/10000\n",
      "52302/52302 [==============================] - 28s 544us/step - loss: 12916646.9797\n",
      "Epoch 7/10000\n",
      "52302/52302 [==============================] - 28s 541us/step - loss: 12910394.4325\n",
      "Epoch 8/10000\n",
      "52302/52302 [==============================] - 28s 542us/step - loss: 12892217.2356\n",
      "Epoch 9/10000\n",
      "52302/52302 [==============================] - 28s 543us/step - loss: 12877508.0019\n",
      "Epoch 10/10000\n",
      "52302/52302 [==============================] - 28s 542us/step - loss: 12870312.5076\n",
      "Epoch 11/10000\n",
      "52302/52302 [==============================] - 28s 541us/step - loss: 12867173.5272\n",
      "Epoch 12/10000\n",
      "52302/52302 [==============================] - 28s 541us/step - loss: 12858491.4174\n",
      "Epoch 13/10000\n",
      "52302/52302 [==============================] - 28s 540us/step - loss: 12848267.9084\n",
      "Epoch 14/10000\n",
      "52302/52302 [==============================] - 28s 543us/step - loss: 12835168.6803\n",
      "Epoch 15/10000\n",
      "52302/52302 [==============================] - 28s 541us/step - loss: 12826287.0748\n",
      "Epoch 16/10000\n",
      "52302/52302 [==============================] - 28s 542us/step - loss: 12903391.0195\n",
      "Epoch 17/10000\n",
      "52302/52302 [==============================] - 28s 543us/step - loss: 12854380.9918\n",
      "Epoch 18/10000\n",
      "52302/52302 [==============================] - 28s 541us/step - loss: 12818790.7785\n",
      "Epoch 19/10000\n",
      "52302/52302 [==============================] - 28s 536us/step - loss: 12804368.2568\n",
      "Epoch 20/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12782651.2541\n",
      "Epoch 21/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12767107.6795\n",
      "Epoch 22/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12741685.5533\n",
      "Epoch 23/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12724712.3329\n",
      "Epoch 24/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 12721097.8044\n",
      "Epoch 25/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12704130.0960\n",
      "Epoch 26/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12879885.0220\n",
      "Epoch 27/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12812351.8863\n",
      "Epoch 28/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 12749397.7892\n",
      "Epoch 29/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12690184.7957\n",
      "Epoch 30/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12640726.2065\n",
      "Epoch 31/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12623087.2152\n",
      "Epoch 32/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12599307.8434\n",
      "Epoch 33/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12563324.0929\n",
      "Epoch 34/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12841683.7794\n",
      "Epoch 35/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12797372.4239\n",
      "Epoch 36/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12654192.6819\n",
      "Epoch 37/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 12547428.8343\n",
      "Epoch 38/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 12498734.1541\n",
      "Epoch 39/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12347727.3583\n",
      "Epoch 44/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12321638.0484\n",
      "Epoch 45/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12289993.8737\n",
      "Epoch 46/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12255691.1594\n",
      "Epoch 47/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12228505.1300\n",
      "Epoch 48/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12196560.5128\n",
      "Epoch 49/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12179549.6260\n",
      "Epoch 50/10000\n",
      "32832/52302 [=================>............] - ETA: 10s - loss: 12292902.1092"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52302/52302 [==============================] - 28s 532us/step - loss: 12156216.4744\n",
      "Epoch 51/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12135671.9777\n",
      "Epoch 52/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12107922.1133\n",
      "Epoch 53/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12099919.9138\n",
      "Epoch 54/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 12061234.5653\n",
      "Epoch 55/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12045837.0167\n",
      "Epoch 56/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 127989569.7544\n",
      "Epoch 57/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12901002.0847\n",
      "Epoch 58/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 12777187.3448\n",
      "Epoch 59/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12684249.3225\n",
      "Epoch 60/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 12590458.8691\n",
      "Epoch 61/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12515773.8502\n",
      "Epoch 62/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 12412159.9612\n",
      "Epoch 63/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 12332645.3077\n",
      "Epoch 64/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 12257454.2033\n",
      "Epoch 65/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12578364.8051\n",
      "Epoch 66/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12325761.4553\n",
      "Epoch 67/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 12200643.8730\n",
      "Epoch 68/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12132697.1502\n",
      "Epoch 69/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12093246.8289\n",
      "Epoch 70/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12072115.3841\n",
      "Epoch 71/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12090867.8502\n",
      "Epoch 72/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12025843.6936\n",
      "Epoch 73/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12018496.2124\n",
      "Epoch 74/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12011685.4143\n",
      "Epoch 75/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12000557.3811\n",
      "Epoch 76/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11989592.8459\n",
      "Epoch 77/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 11984733.3361\n",
      "Epoch 78/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11981971.6387\n",
      "Epoch 79/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11978301.5360\n",
      "Epoch 80/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12000981.3240\n",
      "Epoch 81/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11979409.0421\n",
      "Epoch 82/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11968908.6179\n",
      "Epoch 83/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11945623.8908\n",
      "Epoch 84/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 11946890.0029\n",
      "Epoch 85/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11971587.6022\n",
      "Epoch 86/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11891077.7199\n",
      "Epoch 87/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11892286.4764\n",
      "Epoch 88/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 11837195.8870\n",
      "Epoch 89/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11801586.2231\n",
      "Epoch 90/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11741874.6713\n",
      "Epoch 91/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11595496.4605\n",
      "Epoch 92/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11494020.4121\n",
      "Epoch 93/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11423349.3601\n",
      "Epoch 94/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11337335.6519\n",
      "Epoch 95/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11264429.2582\n",
      "Epoch 96/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 11172748.8704\n",
      "Epoch 97/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 1277081011.5939\n",
      "Epoch 98/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12779940.1852\n",
      "Epoch 99/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12588959.2573\n",
      "Epoch 100/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12385868.4615\n",
      "Epoch 101/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12131917.2203\n",
      "Epoch 102/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11878852.8390\n",
      "Epoch 103/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11604503.4158\n",
      "Epoch 104/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 11378510.1713\n",
      "Epoch 105/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11177110.3759\n",
      "Epoch 106/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11375148.6084\n",
      "Epoch 107/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 10852347.4177\n",
      "Epoch 108/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10685816.4983\n",
      "Epoch 109/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10614804.7222\n",
      "Epoch 110/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 10514290.7839\n",
      "Epoch 111/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 10501261.4068\n",
      "Epoch 112/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10479875.7672\n",
      "Epoch 113/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 10461308.4804\n",
      "Epoch 114/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10484384.9808\n",
      "Epoch 115/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 10512944.6992\n",
      "Epoch 116/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 10432624.3787\n",
      "Epoch 117/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 1338309411.2147\n",
      "Epoch 118/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 13709156.8076\n",
      "Epoch 119/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 13630337.3849\n",
      "Epoch 120/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 13567185.5714\n",
      "Epoch 121/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 13436437.9292\n",
      "Epoch 122/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 13101854.3506\n",
      "Epoch 123/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 12523246.1624\n",
      "Epoch 124/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12370944.2629\n",
      "Epoch 125/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12207244.5475\n",
      "Epoch 126/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12012838.5393\n",
      "Epoch 127/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11827798.3459\n",
      "Epoch 128/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11705822.8456\n",
      "Epoch 129/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11555884.9225\n",
      "Epoch 130/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11434548.1126\n",
      "Epoch 131/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11690947.4430\n",
      "Epoch 132/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52302/52302 [==============================] - 28s 533us/step - loss: 12869992.7700\n",
      "Epoch 133/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12729386.3641\n",
      "Epoch 134/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12551849.1805\n",
      "Epoch 135/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12285335.1186\n",
      "Epoch 136/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12085880.1466\n",
      "Epoch 137/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 11727415.4907\n",
      "Epoch 138/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11575221.1373\n",
      "Epoch 139/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11525056.5377\n",
      "Epoch 140/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11401372.2244\n",
      "Epoch 141/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11310840.8144\n",
      "Epoch 142/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11139766.5506\n",
      "Epoch 143/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11068499.0195\n",
      "Epoch 144/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11003700.3320\n",
      "Epoch 145/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10897146.6683\n",
      "Epoch 146/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11764862.0195\n",
      "Epoch 147/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 10963896.9027\n",
      "Epoch 148/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10599720.2291\n",
      "Epoch 149/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 10602842.2742\n",
      "Epoch 150/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 10316154.5311\n",
      "Epoch 151/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 10248782.1567\n",
      "Epoch 152/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 10096295.6265\n",
      "Epoch 153/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10010761.2251\n",
      "Epoch 154/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 9919800.9377\n",
      "Epoch 155/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 9775181.1953\n",
      "Epoch 156/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 9718454.0488\n",
      "Epoch 157/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 9646416.6087\n",
      "Epoch 158/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 9517744.8364\n",
      "Epoch 159/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 9439769.1259\n",
      "Epoch 160/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 9315847.4291\n",
      "Epoch 161/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 9183112.2275\n",
      "Epoch 162/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 9075591.7418\n",
      "Epoch 163/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 13576883.7303\n",
      "Epoch 164/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12772542.2876\n",
      "Epoch 165/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12662368.2192\n",
      "Epoch 166/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 12545662.7758\n",
      "Epoch 167/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 12423913.5391\n",
      "Epoch 168/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12245834.7460\n",
      "Epoch 169/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12070260.4074\n",
      "Epoch 170/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11864506.4980\n",
      "Epoch 171/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11686167.0331\n",
      "Epoch 172/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 11536750.9376\n",
      "Epoch 173/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11368525.0208\n",
      "Epoch 174/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11262957.2796\n",
      "Epoch 175/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 11128577.8295\n",
      "Epoch 176/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10982084.5471\n",
      "Epoch 177/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10813687.8196\n",
      "Epoch 178/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10687997.8382\n",
      "Epoch 179/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10538590.2193\n",
      "Epoch 180/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10375448.7454\n",
      "Epoch 181/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 10245557.8449\n",
      "Epoch 182/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10087759.1753\n",
      "Epoch 183/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 9980691.5771\n",
      "Epoch 184/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 9830965.7933\n",
      "Epoch 185/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 9763707.8135\n",
      "Epoch 186/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 9551896.6737\n",
      "Epoch 187/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 9565352.3473\n",
      "Epoch 188/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 9358899.6744\n",
      "Epoch 189/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 9252457.6866\n",
      "Epoch 190/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 9153056.8686\n",
      "Epoch 191/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 9041037.0889\n",
      "Epoch 192/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 8939814.5146\n",
      "Epoch 193/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 8807117.7572\n",
      "Epoch 194/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 8736756.8455\n",
      "Epoch 195/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 8605704.1452\n",
      "Epoch 196/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 8585006.5163\n",
      "Epoch 197/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 8473646.1157\n",
      "Epoch 198/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 8381269.3104\n",
      "Epoch 199/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 8271847.1700\n",
      "Epoch 200/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 8227389.3923\n",
      "Epoch 201/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 8189305.0736\n",
      "Epoch 202/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 8425354.3795\n",
      "Epoch 203/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 8079621.3825\n",
      "Epoch 204/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 7870483.3369\n",
      "Epoch 205/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 7867190.1617\n",
      "Epoch 206/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 7775317.1811\n",
      "Epoch 207/10000\n",
      "52302/52302 [==============================] - 28s 531us/step - loss: 7798601.4917\n",
      "Epoch 208/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 7675281.3413\n",
      "Epoch 209/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 7625588.6777\n",
      "Epoch 210/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 7613415.5348\n",
      "Epoch 211/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 7459055.2261\n",
      "Epoch 212/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 7421953.2534\n",
      "Epoch 213/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 7353221.9118\n",
      "Epoch 214/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52302/52302 [==============================] - 28s 533us/step - loss: 7304039.3114\n",
      "Epoch 215/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 7305239.1291\n",
      "Epoch 216/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 7319877.1554\n",
      "Epoch 217/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 7184938.2174\n",
      "Epoch 218/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 7103197.9762\n",
      "Epoch 219/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 7016320.4555\n",
      "Epoch 220/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 6995309.9968\n",
      "Epoch 221/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 6994743.0567\n",
      "Epoch 222/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6949829.7487\n",
      "Epoch 223/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 6852302.5007\n",
      "Epoch 224/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 7504786.5287\n",
      "Epoch 225/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6697032.6153\n",
      "Epoch 226/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6647215.5501\n",
      "Epoch 227/10000\n",
      "52302/52302 [==============================] - 28s 531us/step - loss: 6608528.7856\n",
      "Epoch 228/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 6639790.2281\n",
      "Epoch 229/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 6703955.8614\n",
      "Epoch 230/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 6489518.6558\n",
      "Epoch 231/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6486899.1430\n",
      "Epoch 232/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 6541961.2967\n",
      "Epoch 233/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 6490565.8896\n",
      "Epoch 234/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6392010.7181\n",
      "Epoch 235/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6384508.3847\n",
      "Epoch 236/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6297450.7548\n",
      "Epoch 237/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6231528.7299\n",
      "Epoch 238/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6287730.1247\n",
      "Epoch 239/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6146052.9207\n",
      "Epoch 240/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6214438.1498\n",
      "Epoch 241/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 6185313.3262\n",
      "Epoch 242/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 6038252.1317\n",
      "Epoch 243/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5999556.8255\n",
      "Epoch 244/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6003770.9140\n",
      "Epoch 245/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6056833.8193\n",
      "Epoch 246/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5952447.0582\n",
      "Epoch 247/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5954531.7403\n",
      "Epoch 248/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 5974393.9357\n",
      "Epoch 249/10000\n",
      "52302/52302 [==============================] - 28s 529us/step - loss: 5851961.4663\n",
      "Epoch 250/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5764346.8364\n",
      "Epoch 251/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5881081.9567\n",
      "Epoch 252/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 5886871.0095\n",
      "Epoch 253/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 13476954.7640\n",
      "Epoch 254/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 10351647.8269\n",
      "Epoch 255/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 7607282.0126\n",
      "Epoch 256/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 9626725.1800\n",
      "Epoch 257/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 10630458.1373\n",
      "Epoch 258/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 7694804.3747\n",
      "Epoch 259/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 6482774.7877\n",
      "Epoch 260/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 5976234.0375\n",
      "Epoch 261/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5745749.1165\n",
      "Epoch 262/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 5663952.8759\n",
      "Epoch 263/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 5609260.2377\n",
      "Epoch 264/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 126694218.5469\n",
      "Epoch 265/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 11032530.5650\n",
      "Epoch 266/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 8819528.6629\n",
      "Epoch 267/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 7550710.2338\n",
      "Epoch 268/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 6773202.9337\n",
      "Epoch 269/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 6305965.8512\n",
      "Epoch 270/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 6025495.3211\n",
      "Epoch 271/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5902992.5879\n",
      "Epoch 272/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 5810237.0671\n",
      "Epoch 273/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 5689706.7248\n",
      "Epoch 274/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5620000.8016\n",
      "Epoch 275/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5587704.2181\n",
      "Epoch 276/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 5587436.9573\n",
      "Epoch 277/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5611772.2949\n",
      "Epoch 278/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 5540956.5503\n",
      "Epoch 279/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 5565013.1269\n",
      "Epoch 280/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 5551007.6268\n",
      "Epoch 281/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5513460.4816\n",
      "Epoch 282/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5545741.6807\n",
      "Epoch 283/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 5574687.9328\n",
      "Epoch 284/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5542338.3158\n",
      "Epoch 285/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5361337.4227\n",
      "Epoch 286/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5300678.9757\n",
      "Epoch 287/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 5431036.4804\n",
      "Epoch 288/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5432717.3539\n",
      "Epoch 289/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 5284118.5304\n",
      "Epoch 290/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5251485.7997\n",
      "Epoch 291/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5294310.4768\n",
      "Epoch 292/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5250799.0682\n",
      "Epoch 293/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5139582.7535\n",
      "Epoch 294/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 5256211.3920\n",
      "Epoch 295/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 5202811.9361\n",
      "Epoch 296/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52302/52302 [==============================] - 28s 533us/step - loss: 5169255.3469\n",
      "Epoch 297/10000\n",
      "52302/52302 [==============================] - 28s 531us/step - loss: 5065610.6288\n",
      "Epoch 298/10000\n",
      "52302/52302 [==============================] - 28s 531us/step - loss: 5057982.8739\n",
      "Epoch 299/10000\n",
      "52302/52302 [==============================] - 28s 529us/step - loss: 5161910.6347\n",
      "Epoch 300/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5087581.5296\n",
      "Epoch 301/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 5014256.3653\n",
      "Epoch 302/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 5028669.2928\n",
      "Epoch 303/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4999760.4837\n",
      "Epoch 304/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4977804.1617\n",
      "Epoch 305/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4975819.9203\n",
      "Epoch 306/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4899226.9153\n",
      "Epoch 307/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4879035.8194\n",
      "Epoch 308/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4935049.7783\n",
      "Epoch 309/10000\n",
      "52302/52302 [==============================] - 28s 531us/step - loss: 4903607.3790\n",
      "Epoch 310/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 4877372.5277\n",
      "Epoch 311/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 4860530.6499\n",
      "Epoch 312/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 4840076.0133\n",
      "Epoch 313/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4829641.3984\n",
      "Epoch 314/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4787934.7504\n",
      "Epoch 315/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4769455.6864\n",
      "Epoch 316/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4718936.4614\n",
      "Epoch 317/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 4811381.2757\n",
      "Epoch 318/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4736798.8964\n",
      "Epoch 319/10000\n",
      "52302/52302 [==============================] - 28s 531us/step - loss: 4717703.3997\n",
      "Epoch 320/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4757442.4131\n",
      "Epoch 321/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4639346.1282\n",
      "Epoch 322/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4702162.0924\n",
      "Epoch 323/10000\n",
      "52302/52302 [==============================] - 28s 531us/step - loss: 4669700.8747\n",
      "Epoch 324/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 4624750.8351\n",
      "Epoch 325/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4614895.7467\n",
      "Epoch 326/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4696921.5313\n",
      "Epoch 327/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4533754.2642\n",
      "Epoch 328/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4525819.1763\n",
      "Epoch 329/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4534426.5997\n",
      "Epoch 330/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4540210.5473\n",
      "Epoch 331/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4547677.1335\n",
      "Epoch 332/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4508853.0156\n",
      "Epoch 333/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4592350.1456\n",
      "Epoch 334/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4429359.0811\n",
      "Epoch 335/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4536338.8552\n",
      "Epoch 336/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4520869.1781\n",
      "Epoch 337/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4455295.2757\n",
      "Epoch 338/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4392087.1282\n",
      "Epoch 339/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4403686.8416\n",
      "Epoch 340/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4395237.6766\n",
      "Epoch 341/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4356979.8269\n",
      "Epoch 342/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4424562.2445\n",
      "Epoch 343/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4323339.1291\n",
      "Epoch 344/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 4316588.3139\n",
      "Epoch 345/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4392636.0584\n",
      "Epoch 346/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 11817485.3712\n",
      "Epoch 347/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 35188315.5275\n",
      "Epoch 348/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 12301167.8443\n",
      "Epoch 349/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 11132204.8138\n",
      "Epoch 350/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 9920511.3276\n",
      "Epoch 351/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 8756548.6964\n",
      "Epoch 352/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 7543775.8784\n",
      "Epoch 353/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 19704718.0853\n",
      "Epoch 354/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 10758609.4046\n",
      "Epoch 355/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 9444739.3614\n",
      "Epoch 356/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 8380745.3965\n",
      "Epoch 357/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 7426301.8629\n",
      "Epoch 358/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 6589047.9265\n",
      "Epoch 359/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 5971798.6197\n",
      "Epoch 360/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5527538.8331\n",
      "Epoch 361/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 5213802.0776\n",
      "Epoch 362/10000\n",
      "52302/52302 [==============================] - 28s 531us/step - loss: 5025269.9768\n",
      "Epoch 363/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4949305.6286\n",
      "Epoch 364/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4745611.5069\n",
      "Epoch 365/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4681942.8999\n",
      "Epoch 366/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4617194.9770\n",
      "Epoch 367/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4566420.1214\n",
      "Epoch 368/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4546959.8098\n",
      "Epoch 369/10000\n",
      "52302/52302 [==============================] - 28s 530us/step - loss: 4529957.6842\n",
      "Epoch 370/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4526865.8096\n",
      "Epoch 371/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4482483.7748\n",
      "Epoch 372/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 4469656.4886\n",
      "Epoch 373/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4425387.1866\n",
      "Epoch 374/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4400539.6346\n",
      "Epoch 375/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4335010.5676\n",
      "Epoch 376/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 4312458.9719\n",
      "Epoch 377/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4377610.1295\n",
      "Epoch 378/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52302/52302 [==============================] - 28s 533us/step - loss: 4312106.7546\n",
      "Epoch 379/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4228987.2272\n",
      "Epoch 380/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4188462.4049\n",
      "Epoch 381/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 4210675.9458\n",
      "Epoch 382/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 4224354.1801\n",
      "Epoch 383/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4188674.0641\n",
      "Epoch 384/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 4193717.4661\n",
      "Epoch 385/10000\n",
      "52302/52302 [==============================] - 28s 531us/step - loss: 4122693.2180\n",
      "Epoch 386/10000\n",
      "52302/52302 [==============================] - 28s 531us/step - loss: 4115014.4277\n",
      "Epoch 387/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4109485.2036\n",
      "Epoch 388/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4152908.4448\n",
      "Epoch 389/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4156956.1319\n",
      "Epoch 390/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4078234.0717\n",
      "Epoch 391/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 3988012.6766\n",
      "Epoch 392/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 4019399.7215\n",
      "Epoch 393/10000\n",
      "52302/52302 [==============================] - 28s 535us/step - loss: 4010299.0728\n",
      "Epoch 394/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 3994503.7760\n",
      "Epoch 395/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4044578.5634\n",
      "Epoch 396/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 4058216.0301\n",
      "Epoch 397/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3967938.1654\n",
      "Epoch 398/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 3988965.8904\n",
      "Epoch 399/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3957110.4023\n",
      "Epoch 400/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3972060.9736\n",
      "Epoch 401/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 3900339.0788\n",
      "Epoch 402/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3918389.2451\n",
      "Epoch 403/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3944252.4421\n",
      "Epoch 404/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3895276.8278\n",
      "Epoch 405/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3855797.8069\n",
      "Epoch 406/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3861447.1976\n",
      "Epoch 407/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3945773.8411\n",
      "Epoch 408/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 3956290.9395\n",
      "Epoch 409/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3846673.5105\n",
      "Epoch 410/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3816312.5861\n",
      "Epoch 411/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3839529.5821\n",
      "Epoch 412/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3813342.7488\n",
      "Epoch 413/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3837502.0684\n",
      "Epoch 414/10000\n",
      "52302/52302 [==============================] - 28s 531us/step - loss: 3875850.4572\n",
      "Epoch 415/10000\n",
      "52302/52302 [==============================] - 28s 530us/step - loss: 3823687.0622\n",
      "Epoch 416/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 3793533.5347\n",
      "Epoch 417/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3770039.7995\n",
      "Epoch 418/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3734326.3903\n",
      "Epoch 419/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3727579.1373\n",
      "Epoch 420/10000\n",
      "52302/52302 [==============================] - 28s 530us/step - loss: 3745582.6603\n",
      "Epoch 421/10000\n",
      "52302/52302 [==============================] - 28s 533us/step - loss: 3785049.0146\n",
      "Epoch 422/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 3755125.7829\n",
      "Epoch 423/10000\n",
      "52302/52302 [==============================] - 28s 534us/step - loss: 3705772.1564\n",
      "Epoch 424/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 3741331.0997\n",
      "Epoch 425/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 3757486.8723\n",
      "Epoch 426/10000\n",
      "52302/52302 [==============================] - 28s 532us/step - loss: 3726432.5120\n",
      "Epoch 427/10000\n",
      " 8384/52302 [===>..........................] - ETA: 23s - loss: 3451441.8578"
     ]
    }
   ],
   "source": [
    "# Note that `decoder_target_data` needs to be one-hot encoded,\n",
    "# rather than sequences of integers like `decoder_input_data`!\n",
    "model.fit(encoder_input_data, decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs#,\n",
    "          #callbacks=[EarlyStopping(monitor='loss', patience=10)]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Next: inference mode (sampling).\n",
    "# # Here's the drill:\n",
    "# # 1) encode input and retrieve initial decoder state\n",
    "# # 2) run one step of decoder with this initial state\n",
    "# # and a \"start of sequence\" token as target.\n",
    "# # Output will be the next target token\n",
    "# # 3) Repeat with the current target token and current states\n",
    "\n",
    "# # Define sampling models\n",
    "# encoder_model = Model(encoder_inputs, encoder_states)\n",
    "# encoder_model.summary()\n",
    "\n",
    "# decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "# decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "# decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "# decoder_mapped_input = decoder_embedding(decoder_inputs)\n",
    "# decoder_outputs, state_h, state_c = decoder_lstm(decoder_mapped_input, initial_state=decoder_states_inputs)\n",
    "# decoder_states = [state_h, state_c]\n",
    "# decoder_outputs = Flatten()(decoder_outputs)\n",
    "# decoder_outputs = decoder_dense(decoder_outputs)\n",
    "# decoder_model = Model(\n",
    "#     [decoder_inputs] + decoder_states_inputs,\n",
    "#     [decoder_outputs] + decoder_states)\n",
    "# decoder_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = model.predict(input_seq)[0]\n",
    "    decoded_sentence = ''\n",
    "    for i in range(len(states_value)):\n",
    "        int_val = int(round(states_value[i]))\n",
    "        if int_val > 0:\n",
    "            decoded_sentence += id_word_dict[int_val] + ' '\n",
    "            continue\n",
    "        elif int_val < 0:\n",
    "            print('negative number encountered')\n",
    "        \n",
    "        decoded_sentence += '?' + ' '\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for seq_index in range(num_test_samples):\n",
    "    # Take one sequence (part of the training set)\n",
    "    # for trying out decoding.\n",
    "    input_seq = encoder_input_data[seq_index: seq_index + 1]\n",
    "    decoded_sentence = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[seq_index])\n",
    "    print('Decoded sentence:', decoded_sentence)\n",
    "    print('Target sentence:', output_texts[seq_index][1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
